{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8b4671-e3fa-4a09-85aa-5e72cc963624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HitTime</th>\n",
       "      <th>Arc</th>\n",
       "      <th>ShotDistance</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.592350e+12</td>\n",
       "      <td>-101</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.592350e+12</td>\n",
       "      <td>4</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.592350e+12</td>\n",
       "      <td>-68</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.592350e+12</td>\n",
       "      <td>-63</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.592350e+12</td>\n",
       "      <td>-70</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        HitTime   Arc ShotDistance  Cluster\n",
       "1  1.592350e+12  -101          113        0\n",
       "2  1.592350e+12     4          162        0\n",
       "3  1.592350e+12   -68           32        0\n",
       "4  1.592350e+12   -63          115        0\n",
       "5  1.592350e+12   -70          141        0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# קריאת הקובץ\n",
    "data = pd.read_csv(r\"C:\\Users\\guymk\\Downloads\\data13 (1).csv\")\n",
    "\n",
    "# בחירת עמודות רלוונטיות לקלסטרינג: HitTime, Arc, ShotDistance (מהעמודות \"Raw Data\" והעמודות הרלוונטיות)\n",
    "data_filtered = data[['Raw Data', 'Unnamed: 5', 'Unnamed: 28']].copy()\n",
    "\n",
    "# שינוי שמות העמודות למשהו אינטואיטיבי יותר\n",
    "data_filtered.columns = ['HitTime', 'Arc', 'ShotDistance']\n",
    "\n",
    "# מחיקת שורות עם ערכים חסרים בעמודות אלו\n",
    "data_filtered = data_filtered.dropna(subset=['HitTime', 'Arc', 'ShotDistance'])\n",
    "\n",
    "# המרת 'HitTime' לערכים מספריים (בהנחה שזהו timestamp או נתונים מספריים)\n",
    "data_filtered['HitTime'] = pd.to_numeric(data_filtered['HitTime'], errors='coerce')\n",
    "\n",
    "# מחיקת ערכים חסרים\n",
    "data_filtered = data_filtered.dropna(subset=['HitTime', 'Arc', 'ShotDistance'])\n",
    "\n",
    "# נרמול העמודות 'Arc' ו-'ShotDistance' לצורך DBSCAN\n",
    "scaler = StandardScaler()\n",
    "X_filtered_scaled = scaler.fit_transform(data_filtered[['HitTime', 'Arc', 'ShotDistance']])\n",
    "\n",
    "# הרצת DBSCAN על הדאטה המתוקן\n",
    "dbscan_filtered_model = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusters_filtered = dbscan_filtered_model.fit_predict(X_filtered_scaled)\n",
    "\n",
    "# הוספת תוצאות הקלסטרינג לדאטה\n",
    "data_filtered['Cluster'] = clusters_filtered\n",
    "\n",
    "# הצגת התוצאות\n",
    "data_filtered.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a9a30c-e1e4-422c-87f5-0506229835b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DBSCAN\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mace_tools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# קריאת הדאטה\u001b[39;00m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mguymk\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata13 (1).csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ace_tools'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import ace_tools as tools\n",
    "\n",
    "# קריאת הדאטה\n",
    "data = pd.read_csv(r\"C:\\Users\\guymk\\Downloads\\data13 (1).csv\")\n",
    "\n",
    "# סינון והכנת הנתונים (התאמת עמודות)\n",
    "data_filtered = data[['Raw Data', 'Unnamed: 5', 'Unnamed: 28']].copy()\n",
    "data_filtered.columns = ['HitTime', 'Arc', 'ShotDistance']\n",
    "data_filtered = data_filtered.dropna(subset=['HitTime', 'Arc', 'ShotDistance'])\n",
    "\n",
    "# המרת העמודה HitTime לערכים מספריים\n",
    "data_filtered['HitTime'] = pd.to_numeric(data_filtered['HitTime'], errors='coerce')\n",
    "data_filtered = data_filtered.dropna(subset=['HitTime', 'Arc', 'ShotDistance'])\n",
    "\n",
    "# נרמול הנתונים\n",
    "scaler = StandardScaler()\n",
    "X_filtered_scaled = scaler.fit_transform(data_filtered[['HitTime', 'Arc', 'ShotDistance']])\n",
    "\n",
    "# הרצת DBSCAN עם כוונון הפרמטרים:\n",
    "eps_value = 0.4  # אפשר לנסות גם ערכים של 0.3 או 0.5\n",
    "min_samples_value = 5  # אפשר לנסות להגדיל את הערך בהתאם\n",
    "\n",
    "dbscan_optimized = DBSCAN(eps=eps_value, min_samples=min_samples_value)\n",
    "clusters_optimized = dbscan_optimized.fit_predict(X_filtered_scaled)\n",
    "\n",
    "# הוספת הקלאסטרים לדאטה\n",
    "data_filtered['Cluster_Optimized'] = clusters_optimized\n",
    "\n",
    "# הצגת התוצאות עם הקלאסטרים החדשים\n",
    "tools.display_dataframe_to_user(name=\"Optimized DBSCAN Clustering Results\", dataframe=data_filtered)\n",
    "\n",
    "# הצגת השורות הראשונות עם הקלאסטרים\n",
    "print(data_filtered[['HitTime', 'Arc', 'ShotDistance', 'Cluster_Optimized']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e361ec-12f3-4872-916e-bb2615a52f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        HitTime   Arc ShotDistance  Cluster_Optimized\n",
      "1  1.592350e+12  -101          113                  0\n",
      "2  1.592350e+12     4          162                  0\n",
      "3  1.592350e+12   -68           32                  0\n",
      "4  1.592350e+12   -63          115                  0\n",
      "5  1.592350e+12   -70          141                  0\n",
      "            HitTime   Arc ShotDistance  Cluster_Optimized\n",
      "13723  1.598240e+12  -163           56                  2\n",
      "13724  1.598240e+12  -162           78                  2\n",
      "13725  1.598240e+12  -131          104                  2\n",
      "13726  1.598240e+12  -180          164                  2\n",
      "13727  1.598240e+12  -180           32                  2\n",
      "13728  1.598240e+12  -184           93                  2\n",
      "13729  1.598240e+12  -165           92                  2\n",
      "13730  1.598240e+12  -163           71                  2\n",
      "13731  1.598240e+12  -212           26                  2\n",
      "13732  1.598240e+12  -221           32                  2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# קריאת הדאטה\n",
    "data = pd.read_csv(r\"C:\\Users\\guymk\\Downloads\\data13 (1).csv\")  # עדכן את הנתיב בהתאם לצורך\n",
    "\n",
    "# סינון והכנת הנתונים (התאמת עמודות)\n",
    "data_filtered = data[['Raw Data', 'Unnamed: 5', 'Unnamed: 28']].copy()\n",
    "data_filtered.columns = ['HitTime', 'Arc', 'ShotDistance']\n",
    "data_filtered = data_filtered.dropna(subset=['HitTime', 'Arc', 'ShotDistance'])\n",
    "\n",
    "# המרת העמודה HitTime לערכים מספריים\n",
    "data_filtered['HitTime'] = pd.to_numeric(data_filtered['HitTime'], errors='coerce')\n",
    "data_filtered = data_filtered.dropna(subset=['HitTime', 'Arc', 'ShotDistance'])\n",
    "\n",
    "# נרמול הנתונים\n",
    "scaler = StandardScaler()\n",
    "X_filtered_scaled = scaler.fit_transform(data_filtered[['HitTime', 'Arc', 'ShotDistance']])\n",
    "\n",
    "# הרצת DBSCAN עם כוונון הפרמטרים:\n",
    "eps_value = 0.4  # אפשר לנסות גם ערכים של 0.3 או 0.5\n",
    "min_samples_value = 5  # אפשר לנסות להגדיל את הערך בהתאם\n",
    "\n",
    "dbscan_optimized = DBSCAN(eps=eps_value, min_samples=min_samples_value)\n",
    "clusters_optimized = dbscan_optimized.fit_predict(X_filtered_scaled)\n",
    "\n",
    "# הוספת הקלאסטרים לדאטה\n",
    "data_filtered['Cluster_Optimized'] = clusters_optimized\n",
    "\n",
    "# הצגת התוצאות עם הקלאסטרים החדשים\n",
    "print(data_filtered[['HitTime', 'Arc', 'ShotDistance', 'Cluster_Optimized']].head())\n",
    "\n",
    "# אם תרצה לראות יותר שורות מהדאטה\n",
    "print(data_filtered[['HitTime', 'Arc', 'ShotDistance', 'Cluster_Optimized']].tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f6b16-6d04-4e8a-8d54-adee05613057",
   "metadata": {},
   "source": [
    "## Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb15f5c-70e0-43a2-b4e3-633763b5b99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps: 0.3, min_samples: 4, Silhouette Score: 0.040118796688637166\n",
      "eps: 0.3, min_samples: 5, Silhouette Score: 0.1408825949879625\n",
      "eps: 0.3, min_samples: 6, Silhouette Score: 0.158368243393923\n",
      "eps: 0.4, min_samples: 4, Silhouette Score: 0.25284284044973326\n",
      "eps: 0.4, min_samples: 5, Silhouette Score: 0.2837533788110633\n",
      "eps: 0.4, min_samples: 6, Silhouette Score: 0.35605466286836707\n",
      "eps: 0.5, min_samples: 4, Silhouette Score: 0.3325196444115179\n",
      "eps: 0.5, min_samples: 5, Silhouette Score: 0.3566897283569976\n",
      "eps: 0.5, min_samples: 6, Silhouette Score: 0.3566736284559819\n",
      "eps: 0.6, min_samples: 4, Silhouette Score: 0.33387520909455176\n",
      "eps: 0.6, min_samples: 5, Silhouette Score: 0.3568447905157725\n",
      "eps: 0.6, min_samples: 6, Silhouette Score: 0.3568755473227302\n",
      "\n",
      "Best eps: 0.6, Best min_samples: 6, Best Silhouette Score: 0.3568755473227302\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# קריאת הדאטה\n",
    "data = pd.read_csv(r\"C:\\Users\\guymk\\Downloads\\data13 (1).csv\")  # עדכן את הנתיב בהתאם לצורך\n",
    "\n",
    "# סינון והכנת הנתונים (התאמת עמודות)\n",
    "data_filtered = data[['Raw Data', 'Unnamed: 5', 'Unnamed: 28']].copy()\n",
    "data_filtered.columns = ['HitTime', 'Arc', 'ShotDistance']\n",
    "data_filtered = data_filtered.dropna(subset=['HitTime', 'Arc', 'ShotDistance'])\n",
    "\n",
    "# המרת העמודה HitTime לערכים מספריים\n",
    "data_filtered['HitTime'] = pd.to_numeric(data_filtered['HitTime'], errors='coerce')\n",
    "data_filtered = data_filtered.dropna(subset=['HitTime', 'Arc', 'ShotDistance'])\n",
    "\n",
    "# נרמול הנתונים\n",
    "scaler = StandardScaler()\n",
    "X_filtered_scaled = scaler.fit_transform(data_filtered[['HitTime', 'Arc', 'ShotDistance']])\n",
    "\n",
    "# טווח של ערכי eps ו-min_samples\n",
    "eps_values = [0.3, 0.4, 0.5, 0.6]  # נסה מספר ערכים ל-eps\n",
    "min_samples_values = [4, 5, 6]  # נסה מספר ערכים ל-min_samples\n",
    "\n",
    "# איחסון התוצאות\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "best_sil_score = -1\n",
    "\n",
    "# הרצת DBSCAN עבור כל שילוב של eps ו-min_samples\n",
    "for eps_value in eps_values:\n",
    "    for min_samples_value in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps_value, min_samples=min_samples_value)\n",
    "        labels = dbscan.fit_predict(X_filtered_scaled)\n",
    "        \n",
    "        # נבדוק אם יש יותר מקלאסטר אחד כדי לחשב את Silhouette Score\n",
    "        if len(set(labels)) > 1:  # נוודא שיש יותר מקלאסטר אחד (לא רק רעש)\n",
    "            sil_score = silhouette_score(X_filtered_scaled, labels)\n",
    "            print(f'eps: {eps_value}, min_samples: {min_samples_value}, Silhouette Score: {sil_score}')\n",
    "            \n",
    "            # נשמור את הערכים הטובים ביותר\n",
    "            if sil_score > best_sil_score:\n",
    "                best_sil_score = sil_score\n",
    "                best_eps = eps_value\n",
    "                best_min_samples = min_samples_value\n",
    "\n",
    "# תוצאות סופיות\n",
    "print(f'\\nBest eps: {best_eps}, Best min_samples: {best_min_samples}, Best Silhouette Score: {best_sil_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315281b1-af24-4a24-b4f8-f5b077926870",
   "metadata": {},
   "source": [
    "Based on the image you provided, we can observe the results of the DBSCAN algorithm after clustering your shot data, which includes variables like Arc (shot angle) and ShotDistance (distance of the shot), and the assigned clusters (Cluster_Optimized).\n",
    "\n",
    "Analysis of the Results:\n",
    "Cluster_Optimized:\n",
    "\n",
    "At least two primary clusters (0 and 2) were identified based on the similarity of the shot characteristics.\n",
    "These clusters group together shots with similar features, such as shot angle (Arc) and shot distance (ShotDistance).\n",
    "Cluster 0:\n",
    "\n",
    "Characteristics: Medium shot angles (e.g., -101, -68) and relatively longer shot distances (e.g., 113, 115).\n",
    "The shots in this cluster appear to represent mid-range shots with medium shot angles.\n",
    "Cluster 2:\n",
    "\n",
    "Characteristics: More extreme angles (e.g., -163 to -221) and variable shot distances (e.g., 56 to 164).\n",
    "The shots in this cluster indicate sharper angles and varying shot distances, but they tend to be closer to specific positions on the court.\n",
    "## Conclusions:\n",
    "Grouping by Angle and Distance: The algorithm successfully identified two distinct clusters based on the shot angle and distance. Shots in Cluster 0 tend to have less extreme angles and medium to close shot distances, whereas Cluster 2 includes more extreme angles and varying shot distances.\n",
    "\n",
    "Differences in Shot Style: The differences between the clusters suggest different shooting techniques or positions on the court. Cluster 0 may describe shots that are closer to the basket with more standard angles, while Cluster 2 could represent more challenging, distant shots or shots taken under different circumstances.\n",
    "\n",
    "Tactical Improvement: If this data reflects game performance, shots in Cluster 2 might be less accurate because of the sharp angles. A deeper analysis could look at the success rates of shots from each cluster and offer insights into the efficiency of these shot types.\n",
    "\n",
    "Training Opportunities: The shots in Cluster 2 with extreme angles could indicate areas where players may need to work on accuracy from long distances or learn to adjust the balance between angle and shot distance to improve success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b8c750-c339-45ae-adff-b2a7cef4a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      " 0    8085\n",
      " 1    5550\n",
      "-1      97\n",
      "Name: count, dtype: int64\n",
      "Silhouette Score for best parameters: 0.3566736284559819\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# קריאת הדאטה\n",
    "data = pd.read_csv(r\"C:\\Users\\guymk\\Downloads\\data13 (1).csv\")  # עדכן את הנתיב בהתאם לצורך\n",
    "\n",
    "# סינון והכנת הנתונים (התאמת עמודות)\n",
    "data_filtered = data[['Raw Data', 'Unnamed: 5', 'Unnamed: 28']].copy()\n",
    "data_filtered.columns = ['HitTime', 'Arc', 'ShotDistance']\n",
    "data_filtered = data_filtered.dropna(subset=['HitTime', 'Arc', 'ShotDistance'])\n",
    "\n",
    "# המרת העמודה HitTime לערכים מספריים\n",
    "data_filtered['HitTime'] = pd.to_numeric(data_filtered['HitTime'], errors='coerce')\n",
    "data_filtered = data_filtered.dropna(subset=['HitTime', 'Arc', 'ShotDistance'])\n",
    "\n",
    "# נרמול הנתונים\n",
    "scaler = StandardScaler()\n",
    "X_filtered_scaled = scaler.fit_transform(data_filtered[['HitTime', 'Arc', 'ShotDistance']])\n",
    "\n",
    "# הרצת DBSCAN עם הערכים שנבחרו\n",
    "best_eps = 0.5\n",
    "best_min_samples = 6\n",
    "\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "labels = dbscan.fit_predict(X_filtered_scaled)\n",
    "\n",
    "# הוספת התוויות לדאטה המקורי\n",
    "data_filtered['Cluster'] = labels\n",
    "\n",
    "# הצגת תוצאות הקלסטרינג\n",
    "print(data_filtered['Cluster'].value_counts())\n",
    "\n",
    "# חישוב Silhouette Score עבור התוצאות הטובות ביותר\n",
    "sil_score = silhouette_score(X_filtered_scaled, labels)\n",
    "print(f'Silhouette Score for best parameters: {sil_score}')\n",
    "\n",
    "# שמירת תוצאות הקלסטרינג לתוך קובץ חדש\n",
    "data_filtered.to_csv('clustered_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5703fe4-2054-4088-816d-5e49d9a420f1",
   "metadata": {},
   "source": [
    "## purpose:\n",
    "We performed a clustering analysis (DBSCAN) on data of shots to the basket with the aim of understanding whether the shots can be divided into different groups based on different characteristics such as the shot time (HitTime), arc (Arc) and distance from the center (Shot distance from center). The goal was to identify groups of shots that can be characterized in a different way and to examine the way in which the shots are distributed in space.\n",
    "\n",
    "## Clustering results:\n",
    "Two main clusters: The algorithm identified two main clusters:\n",
    "\n",
    "Cluster 0: contains 8085 shots.\n",
    "Cluster 1: contains 5550 shots.\n",
    "A large amount of injections was divided into two main groups, so that we have a relatively clear division between the injections.\n",
    "\n",
    "Minimal noise: only 97 shots were classified as noise (Cluster -1). This means that most of the shots are within ordered groups, and it can be seen that they are not defined as isolated points in space, which indicates that the parameters were well chosen to reduce the amount of isolated points.\n",
    "\n",
    "## Silhouette Score:\n",
    "\n",
    "The score obtained for the clustering is 0.3567, indicating that the distribution is reasonable but not perfect. The score indicates that the groups are relatively close to each other in space, but there is some overlap between the groups.\n",
    "It is important to remember that this score indicates a moderate division - the clusters exist, but there may be an overlap in the characteristics of the shots between the different groups.\n",
    "Interpretation of the findings:\n",
    "The division into two main clusters can offer interesting insights into the patterns of shots into the basket:\n",
    "\n",
    "Different clusters of shots: the two groups produced by the DBSCAN may reflect different types of shots in terms of characteristics such as the arc of the shot and distance from the shot position to the center. It is possible that the first group (Cluster 0) reflects shots with a high arc or a specific location, while the second group (Cluster 1) represents shots of a different type.\n",
    "\n",
    "Low noise: only a small amount of shots were detected as noise, meaning most shots clearly belong to one of the two groups. This result indicates that the data is well organized and there are not many isolated shots that cannot be associated.\n",
    "\n",
    "## The meaning of the silhouette score:\n",
    "\n",
    "The score obtained (0.3567) indicates that there is no perfect distribution between the shots, which could imply that there is no clear and sharp difference between the types of shots, or that it is possible that the shots are gradually integrated into the space.\n",
    "Another possibility is that there is a continuous space where the shots are not unambiguously associated with separate groups.\n",
    "Conclusions and summary:\n",
    "Potential for clear division: We were able to divide the shots into two main groups, which indicates that there are certain patterns in the shots that can differentiate between different types of shots.\n",
    "The little noise indicates good quality: a small amount of shots that failed to belong to any cluster indicates that the data is well organized and insights can be extracted from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056275f-cd49-4195-9e53-802085593d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
